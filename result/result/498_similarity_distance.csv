node1,node2,similarity,distance
VLN,Vision-and-Language Navigation,-0.1765,1.534
Vision-and-Language Navigation,cross-modal attention,0.2489,1.2256
Vision-and-Language Navigation,egocentric observations,0.006,1.4099
VLN,cross-modal attention,-0.0432,1.4444
VLN,egocentric observations,-0.1841,1.5389
cross-modal attention,egocentric observations,0.1225,1.3248
Vision-and-Language Navigation,spatial representations,0.0275,1.3946
VLN,spatial representations,-0.0776,1.468
cross-modal attention,spatial representations,0.0497,1.3786
egocentric observations,spatial representations,0.0742,1.3607
Vision-and-Language Navigation,cross-modal map learning,0.1658,1.2917
Vision-and-Language Navigation,predict,-0.1808,1.5368
Vision-and-Language Navigation,way-points,0.9286,0.3778
VLN,cross-modal map learning,-0.0859,1.4737
VLN,predict,-0.1567,1.521
VLN,way-points,-0.1646,1.5262
cross-modal attention,cross-modal map learning,0.9764,0.2172
cross-modal attention,predict,-0.0774,1.4679
cross-modal attention,way-points,0.3214,1.165
cross-modal map learning,egocentric observations,0.1503,1.3036
egocentric observations,predict,-0.2523,1.5826
egocentric observations,way-points,-0.0416,1.4433
cross-modal map learning,spatial representations,-0.0691,1.4623
predict,spatial representations,-0.1356,1.507
spatial representations,way-points,-0.1406,1.5104
cross-modal map learning,predict,0.0688,1.3647
cross-modal map learning,way-points,0.2694,1.2088
predict,way-points,0.0422,1.3841
VLN-CE benchmark,Vision-and-Language Navigation,-0.079,1.469
VLN,VLN-CE benchmark,-0.005,1.4177
VLN-CE benchmark,cross-modal attention,0.2157,1.2525
VLN-CE benchmark,cross-modal map learning,0.2417,1.2315
VLN-CE benchmark,predict,-0.1648,1.5263
VLN-CE benchmark,way-points,-0.1125,1.4917
