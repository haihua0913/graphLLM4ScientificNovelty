node1,node2,similarity,distance
Imitation learning,maximum margin structured prediction,-0.059,1.4553
Imitation learning,policies,-0.131,1.504
maximum margin structured prediction,policies,0.0065,1.4096
Imitation learning,MDP,-0.3099,1.6186
Imitation learning,optimal policy,-0.2734,1.5959
MDP,maximum margin structured prediction,-0.1212,1.4974
maximum margin structured prediction,optimal policy,-0.0201,1.4283
MDP,policies,0.8922,0.4643
optimal policy,policies,0.9526,0.3079
MDP,optimal policy,0.9452,0.3311
maximum margin structured prediction,subgradient method,0.7742,0.672
inference,maximum margin structured prediction,0.2148,1.2531
policies,subgradient method,-0.1088,1.4892
inference,policies,0.0818,1.3551
MDP,subgradient method,-0.244,1.5774
MDP,inference,-0.114,1.4927
optimal policy,subgradient method,-0.0677,1.4613
inference,optimal policy,-0.027,1.4332
inference,subgradient method,-0.0252,1.4319
dynamic programming,policies,0.0737,1.3611
MDP,dynamic programming,-0.0691,1.4622
dynamic programming,optimal policy,0.1097,1.3344
dynamic programming,subgradient method,-0.0183,1.4271
dynamic programming,inference,0.2842,1.1965
policies,route planning,-0.1216,1.4978
outdoor mobile robots,policies,-0.0424,1.4439
route planning,subgradient method,-0.2785,1.5991
outdoor mobile robots,subgradient method,-0.0209,1.4289
inference,route planning,0.2814,1.1988
inference,outdoor mobile robots,0.1245,1.3233
dynamic programming,route planning,0.9325,0.3673
dynamic programming,outdoor mobile robots,0.5679,0.9296
outdoor mobile robots,route planning,0.5539,0.9446
