{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Requirement already satisfied: torch_geometric in /root/miniforge3/lib/python3.10/site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in /root/miniforge3/lib/python3.10/site-packages (from torch_geometric) (3.11.18)\n",
      "Requirement already satisfied: fsspec in /root/miniforge3/lib/python3.10/site-packages (from torch_geometric) (2025.3.2)\n",
      "Requirement already satisfied: jinja2 in /root/miniforge3/lib/python3.10/site-packages (from torch_geometric) (3.1.3)\n",
      "Requirement already satisfied: numpy in /root/miniforge3/lib/python3.10/site-packages (from torch_geometric) (1.26.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /root/miniforge3/lib/python3.10/site-packages (from torch_geometric) (6.0.0)\n",
      "Requirement already satisfied: pyparsing in /root/miniforge3/lib/python3.10/site-packages (from torch_geometric) (3.2.3)\n",
      "Requirement already satisfied: requests in /root/miniforge3/lib/python3.10/site-packages (from torch_geometric) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /root/miniforge3/lib/python3.10/site-packages (from torch_geometric) (4.66.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /root/miniforge3/lib/python3.10/site-packages (from aiohttp->torch_geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/miniforge3/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /root/miniforge3/lib/python3.10/site-packages (from aiohttp->torch_geometric) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniforge3/lib/python3.10/site-packages (from aiohttp->torch_geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniforge3/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniforge3/lib/python3.10/site-packages (from aiohttp->torch_geometric) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniforge3/lib/python3.10/site-packages (from aiohttp->torch_geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/miniforge3/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.20.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniforge3/lib/python3.10/site-packages (from jinja2->torch_geometric) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniforge3/lib/python3.10/site-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniforge3/lib/python3.10/site-packages (from requests->torch_geometric) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniforge3/lib/python3.10/site-packages (from requests->torch_geometric) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniforge3/lib/python3.10/site-packages (from requests->torch_geometric) (2024.7.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /root/miniforge3/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting openpyxl\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/c0/da/977ded879c29cbd04de313843e76868e6e13408a94ed6b987245dc7c8506/openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/c1/8b/5fe2cc11fee489817272089c4203e679c63b570a5aaeb18d852ae3cbba6a/et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting huggingface_hub\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/46/7b/98daa50a2db034cab6cd23a3de04fa2358cb691593d28e9130203eb7a805/huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
      "Requirement already satisfied: filelock in /root/miniforge3/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniforge3/lib/python3.10/site-packages (from huggingface_hub) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /root/miniforge3/lib/python3.10/site-packages (from huggingface_hub) (24.0)\n",
      "Collecting pyyaml>=5.1 (from huggingface_hub)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/6b/4e/1523cb902fd98355e2e9ea5e5eb237cbc5f3ad5f3075fa65087aa0ecb669/PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m751.2/751.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm-:--:--\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /root/miniforge3/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /root/miniforge3/lib/python3.10/site-packages (from huggingface_hub) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniforge3/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface_hub)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/6d/2f/6cad7b5fe86b7652579346cb7f85156c11761df26435651cbba89376cd2c/hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /root/miniforge3/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniforge3/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniforge3/lib/python3.10/site-packages (from requests->huggingface_hub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniforge3/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.7.4)\n",
      "Installing collected packages: pyyaml, hf-xet, huggingface_hub\n",
      "Successfully installed hf-xet-1.1.5 huggingface_hub-0.33.4 pyyaml-6.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting transformers\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/96/88/beb33a79a382fcd2aed0be5222bdc47f41e4bfe7aaa90ae1374f1d8ea2af/transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /root/miniforge3/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /root/miniforge3/lib/python3.10/site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniforge3/lib/python3.10/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniforge3/lib/python3.10/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniforge3/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/f2/98/26d3830875b53071f1f0ae6d547f1d98e964dd29ad35cbf94439120bb67a/regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /root/miniforge3/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/c5/74/f41a432a0733f61f3d21b288de6dfa78f7acff309c6f0f323b2833e9189f/tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/a6/f8/dae3421624fcc87a89d42e1898a798bc7ff72c61f38973a65d60df8f124c/safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/miniforge3/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniforge3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniforge3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /root/miniforge3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniforge3/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniforge3/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniforge3/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniforge3/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n",
      "Installing collected packages: safetensors, regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.2 transformers-4.53.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting pandas\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/2c/95/79ab37aa4c25d1e7df953dde407bb9c3e4ae47d154bc0dd1692f3a6dcf8c/pandas-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /root/miniforge3/lib/python3.10/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniforge3/lib/python3.10/site-packages (from pandas) (2.9.0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/81/c4/34e93fe5f5429d7570ec1fa436f1986fb1f00c3e0f43a589fe2bbcd22c3f/pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/5c/23/c7abc0ca0a1526a0774eca151daeb8de62ec457e77262b66b359c3c7679e/tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniforge3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.3.1 pytz-2025.2 tzdata-2025.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting scikit-learn\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/fb/f6/800cb3243dd0137ca6d98df8c9d539eb567ba0a0a39ecd245c33fab93510/scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.0 in /root/miniforge3/lib/python3.10/site-packages (from scikit-learn) (1.26.3)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/8e/6d/41991e503e51fc1134502694c5fa7a1671501a17ffa12716a4a9151af3df/scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/7d/4f/1195bbac8e0c2acc5f740661631d8d750dc38d4a32b23ee5df3cde6f4e0d/joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/32/d5/f9a850d79b0851d1d4ef6456097579a9005b31fea68726a4ae5f2d82ddd9/threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.7.0 scipy-1.15.3 threadpoolctl-3.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Requirement already satisfied: torch in /root/miniforge3/lib/python3.10/site-packages (2.0.0+cu117)\n",
      "Collecting torch\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/0a/7c/0a5b3aee977596459ec45be2220370fde8e017f651fecc40522fd478cb1e/torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl (821.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /root/miniforge3/lib/python3.10/site-packages (0.15.1+cu117)\n",
      "Collecting torchvision\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/e2/99/db71d62d12628111d59147095527a0ab492bdfecfba718d174c04ae6c505/torchvision-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl (7.5 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchaudio in /root/miniforge3/lib/python3.10/site-packages (2.0.1+cu117)\n",
      "Collecting torchaudio\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/7d/dc/7569889c1fc95ebf18b0295bc4fdebafbbb89ba9e0018c7e9b0844bae011/torchaudio-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /root/miniforge3/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /root/miniforge3/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/a2/09/77d55d46fd61b4a135c444fc97158ef34a095e5681d0a6c10b75bf356191/sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /root/miniforge3/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /root/miniforge3/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /root/miniforge3/lib/python3.10/site-packages (from torch) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/75/2e/46030320b5a80661e88039f59060d1790298b4718944a65a7f2aeda3d9e9/nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/e1/23/e717c5ac26d26cf39a27fbc076240fad2e3b817e5889d671b67f4f9f49c5/nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/49/60/7b6497946d74bcf1de852a21824d63baad12cd417db4195fc1bfe59db953/nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/2a/78/4535c9c7f859a64781e43c969a3a7e84c54634e319a996d43ef32ce46f83/nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/af/eb/ff4b8c503fa1f1796679dce648854d58751982426e4e4b37d6fce49d259c/nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/8f/16/73727675941ab8e6ffd86ca3a4b7b47065edcca7a997920b831f8147c99d/nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/73/1b/44a01c4e70933637c93e6e1a8063d1e998b50213a6b65ac5a9169c47e98e/nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/f0/6e/c2cf12c9ff8b872e92b4a5740701e51ff17689c4d726fca91875b07f655d/nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/06/1e/b8b7c2f4099a37b96af5c9bb158632ea9e5d9d27d7391d7eb8fc45236674/nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/3b/9a/72ef35b399b0e183bc2e8f6f558036922d453c4d8237dab26c666a04244b/nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/67/ca/f42388aed0fddd64ade7493dbba36e1f534d4e6fdbdd355c6a90030ae028/nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/56/9a/fff8376f8e3d084cd1530e1ef7b879bb7d6d265620c95c1b322725c694f4/nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/9d/d7/c5383e47c7e9bf1c99d5bd2a8c935af2b6d705ad831a7ec5c97db4d82f4f/nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/b2/66/cc9876340ac68ae71b15c743ddb13f8b30d5244af344ec8322b449e35426/nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.3.1 (from torch)\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/8d/a9/549e51e9b1b2c9b854fd761a1d23df0ba2fbc60bd0c13b489ffa518cfcb7/triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=40.8.0 in /root/miniforge3/lib/python3.10/site-packages (from triton==3.3.1->torch) (69.5.1)\n",
      "Requirement already satisfied: numpy in /root/miniforge3/lib/python3.10/site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /root/miniforge3/lib/python3.10/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniforge3/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniforge3/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.0.0\n",
      "    Uninstalling triton-2.0.0:\n",
      "      Successfully uninstalled triton-2.0.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.0+cu117\n",
      "    Uninstalling torch-2.0.0+cu117:\n",
      "      Successfully uninstalled torch-2.0.0+cu117\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.15.1+cu117\n",
      "    Uninstalling torchvision-0.15.1+cu117:\n",
      "      Successfully uninstalled torchvision-0.15.1+cu117\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.0.1+cu117\n",
      "    Uninstalling torchaudio-2.0.1+cu117:\n",
      "      Successfully uninstalled torchaudio-2.0.1+cu117\n",
      "Successfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.1 torchaudio-2.7.1 torchvision-0.22.1 triton-3.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "from torch_geometric.data import Data\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def safe_eval(cell):\n",
    "    if isinstance(cell, str):\n",
    "        return eval(cell, {'Counter': Counter})\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®ä½“å¯¹é½éƒ¨åˆ†\n",
    "def duiqi():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çŸ¥è¯†è¡¨ç¤º(åˆå§‹åŒ–)\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\", cache_dir='/workspace/scibert_scivocab_uncased')\n",
    "#bert_model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\", cache_dir='/workspace/scibert_scivocab_uncased')\n",
    "\n",
    "# ä½¿ç”¨ SciBERT è¿›è¡Œåˆå§‹åŒ–\n",
    "model_path = \"/workspace/scibert_scivocab_uncased\"\n",
    "#model_path = \"/workspace/scideberta-cs\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
    "bert_model = AutoModel.from_pretrained(model_path, local_files_only=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bert_model = bert_model.to(device)\n",
    "\n",
    "def get_embeddings(text_list, method = \"mean\"):\n",
    "    \"\"\"å¯¹æ‰€æœ‰èŠ‚ç‚¹çš„æ–‡æœ¬ä½¿ç”¨ BERT æå– 768 ç»´å‘é‡\"\"\"\n",
    "    inputs = tokenizer(text_list, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n",
    "\n",
    "    if method == \"mean\":\n",
    "        # å¹³å‡æ± åŒ–\n",
    "        embeddings = last_hidden_state[:, 1:-1, :].mean(dim=1)  # å»æ‰ç¬¬ä¸€ä¸ª [CLS] å’Œæœ€åä¸€ä¸ª [SEP]\n",
    "    elif method == \"max\":\n",
    "        # æœ€å¤§æ± åŒ–\n",
    "        embeddings = torch.max(last_hidden_state[:, 1:-1, :], dim=1).values\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "\n",
    "import torch.nn as nn\n",
    "class GATWithBERT(nn.Module):\n",
    "    def __init__(self, out_dim=8):\n",
    "        super(GATWithBERT, self).__init__()\n",
    "        # å®šä¹‰GATå±‚\n",
    "        self.conv1 = GATConv(768, 256, heads=4, dropout=0.1)\n",
    "        self.conv2 = GATConv(256 * 4, 64, heads=2, dropout=0.1)\n",
    "        self.conv3 = GATConv(64 * 2, 32, heads=2, dropout=0.1)\n",
    "        self.conv4 = GATConv(32 * 2, 16, heads=1, dropout=0.1)\n",
    "        self.conv5 = GATConv(16 * 1, out_dim, heads=1, concat=False, dropout=0.0)\n",
    "\n",
    "        # Bnormalizationå±‚\n",
    "        self.norm1 = nn.BatchNorm1d(256 * 4)\n",
    "        self.norm2 = nn.BatchNorm1d(64 * 2)\n",
    "        self.norm3 = nn.BatchNorm1d(32 * 2)\n",
    "        self.norm4 = nn.BatchNorm1d(16 * 1)\n",
    "        self.norm5 = nn.BatchNorm1d(out_dim)\n",
    "\n",
    "        # Dropoutå±‚\n",
    "        self.dropout = nn.Dropout(0.1)  # Dropout é˜²æ­¢è¿‡æ‹Ÿåˆ\n",
    "\n",
    "        # æ·»åŠ çº¿æ€§å˜åŒ–ï¼Œä½¿åŸå§‹ç‰¹å¾ç»´åº¦åŒ¹é…è¾“å‡ºç‰¹å¾ï¼Œä¿ç•™åŸå§‹ç‰¹å¾\n",
    "        self.proj = nn.Linear(768, out_dim)\n",
    "        self.alpha = 0.0  #åŸå§‹ç‰¹å¾ä¿æŒå¤šå°‘\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x_res = self.proj(x)  # æ®‹å·®è¿æ¥\n",
    "        # ç¬¬ä¸€å±‚\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # ç¬¬äºŒå±‚\n",
    "        x = F.elu(self.conv2(x, edge_index))\n",
    "        x = self.norm2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # ç¬¬ä¸‰å±‚\n",
    "        x = F.elu(self.conv3(x, edge_index))\n",
    "        x = self.norm3(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # ç¬¬å››å±‚\n",
    "        x = F.elu(self.conv4(x, edge_index))\n",
    "        x = self.norm4(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # ç¬¬äº”å±‚ï¼ˆæœ€ç»ˆè¾“å‡ºï¼‰\n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = self.norm5(x)\n",
    "\n",
    "        #x = (1-self.alpha)*x + self.alpha*x_res  # æ®‹å·®è¿æ¥\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "\n",
    "# =====éšå³æ¸¸èµ°è®¡ç®—loss=====\n",
    "def build_adj_list(edge_index, num_nodes):\n",
    "    \"\"\" é¢„æ„å»ºé‚»æ¥è¡¨ï¼Œä»¥åŠ é€Ÿéšæœºæ¸¸èµ° \"\"\"\n",
    "    adj_list = {i: set() for i in range(num_nodes)}\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        u, v = edge_index[:, i]\n",
    "        adj_list[u.item()].add(v.item())\n",
    "        adj_list[v.item()].add(u.item())\n",
    "    return adj_list\n",
    "def random_walk(adj_list, num_nodes, walk_length=5, num_walks=5):\n",
    "    \"\"\" é«˜æ•ˆéšæœºæ¸¸èµ°ï¼Œå‡å°‘ä¸å¿…è¦çš„æ•°æ®ç»“æ„è½¬æ¢ \"\"\"\n",
    "    walks = []\n",
    "    for _ in range(num_walks):\n",
    "        for node in range(num_nodes):\n",
    "            walk = [node]\n",
    "            for _ in range(walk_length - 1):\n",
    "                neighbors = list(adj_list[walk[-1]])\n",
    "                if len(neighbors) == 0:\n",
    "                    break\n",
    "                walk.append(random.choice(neighbors))\n",
    "            walks.append(walk)\n",
    "    return walks\n",
    "def batch_cosine_similarity(a, b):\n",
    "    \"\"\" é«˜æ•ˆæ‰¹é‡è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ \"\"\"\n",
    "    return F.cosine_similarity(a, b, dim=1)\n",
    "# è®¡ç®—æŸå¤±å‡½æ•°\n",
    "def unsupervised_loss(embeddings, edge_index, num_nodes, neg_sample_size=5):\n",
    "    \"\"\"\n",
    "    è®¡ç®—åŸºäºéšæœºæ¸¸èµ°çš„æ— ç›‘ç£å¯¹æ¯”æŸå¤±\n",
    "    \"\"\"\n",
    "    adj_list = build_adj_list(edge_index, num_nodes)\n",
    "    walks = random_walk(adj_list, num_nodes, walk_length=5, num_walks=10)\n",
    "    loss = 0\n",
    "    num_pairs = 0\n",
    "    for walk in walks:\n",
    "        for i in range(len(walk) - 1): # é¿å…è¶…å‡ºç´¢å¼•\n",
    "            node = walk[i]\n",
    "            pos_node = walk[i + 1] # æ­£æ ·æœ¬\n",
    "\n",
    "            # è®¡ç®—æ­£æ ·æœ¬ç›¸ä¼¼åº¦\n",
    "            pos_sim = batch_cosine_similarity(embeddings[node].unsqueeze(0), embeddings[pos_node].unsqueeze(0))\n",
    "\n",
    "            # è´Ÿæ ·æœ¬é‡‡æ ·\n",
    "            neg_samples = torch.randint(0, num_nodes, (neg_sample_size,), device=embeddings.device)\n",
    "            neg_sim = batch_cosine_similarity(embeddings[node].unsqueeze(0), embeddings[neg_samples])\n",
    "\n",
    "            # è®¡ç®—å¯¹æ¯”æŸå¤±\n",
    "            loss += -torch.log(torch.exp(pos_sim) / (torch.exp(pos_sim) + torch.exp(neg_sim).sum()))\n",
    "            num_pairs += 1\n",
    "\n",
    "    return loss / num_pairs  # å½’ä¸€åŒ–\n",
    "\n",
    "def laplacian_loss(node_embeddings, edge_index, edge_weight=None):\n",
    "    loss = 0\n",
    "    num_edges = edge_index.shape[1]\n",
    "    for k in range(num_edges):\n",
    "        i,j= edge_index[0, k], edge_index[1, k]\n",
    "        weight = edge_weight[k] if edge_weight is not None else 1\n",
    "\n",
    "        loss += weight * torch.norm(node_embeddings[i] - node_embeddings[j],p=2)\n",
    "    return loss / num_edges\n",
    "\n",
    "def neighborhood_loss(embeddings, edge_index):\n",
    "    \"\"\" è®¡ç®—å±€éƒ¨é‚»å±…ä¿¡æ¯ä¼ æ’­æŸå¤± \"\"\"\n",
    "    loss = 0\n",
    "    num_edges = edge_index.shape[1]\n",
    "\n",
    "    for k in range(num_edges):\n",
    "        i, j = edge_index[0, k], edge_index[1, k]  # è·å–è¾¹ (i, j)\n",
    "\n",
    "        # è®¡ç®—é‚»å±…ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦\n",
    "        sim = F.cosine_similarity(embeddings[i].unsqueeze(0), embeddings[j].unsqueeze(0), dim=1)\n",
    "\n",
    "        # è®©ç›¸è¿çš„èŠ‚ç‚¹ç›¸ä¼¼\n",
    "        loss += (1 - sim)\n",
    "\n",
    "    return loss / num_edges  # å½’ä¸€åŒ–\n",
    "\n",
    "def contrastive_loss(embeddings, edge_index, num_nodes, neg_sample_size=5):\n",
    "    \"\"\" è®©é‚»å±…æ›´ç›¸ä¼¼ï¼Œéé‚»å±…æ›´ä¸åŒ \"\"\"\n",
    "    loss = 0\n",
    "    num_pairs = 0\n",
    "\n",
    "    for k in range(edge_index.shape[1]):\n",
    "        i, j = edge_index[0, k], edge_index[1, k]  # é‚»å±…èŠ‚ç‚¹\n",
    "\n",
    "        # æ­£æ ·æœ¬ï¼ˆé‚»å±…ç›¸ä¼¼ï¼‰\n",
    "        pos_sim = F.cosine_similarity(embeddings[i].unsqueeze(0), embeddings[j].unsqueeze(0), dim=1)\n",
    "\n",
    "        # è´Ÿæ ·æœ¬ï¼ˆéé‚»å±…å°½å¯èƒ½ä¸åŒï¼‰\n",
    "        neg_samples = torch.randint(0, num_nodes, (neg_sample_size,), device=embeddings.device)\n",
    "        neg_sim = torch.mean(F.cosine_similarity(embeddings[i].unsqueeze(0), embeddings[neg_samples], dim=1))\n",
    "\n",
    "        loss += -torch.log(torch.exp(pos_sim) / (torch.exp(pos_sim) + torch.exp(neg_sim).sum()))\n",
    "        num_pairs += 1\n",
    "\n",
    "    return loss / num_pairs  # å½’ä¸€åŒ–\n",
    "\n",
    "import torch\n",
    "\n",
    "def entropy_loss(embeddings):\n",
    "    \"\"\"è®¡ç®—å…¨å±€ç»“æ„ç†µï¼Œé¼“åŠ±å…¨å±€å¤šæ ·æ€§\"\"\"\n",
    "    # å½’ä¸€åŒ–ï¼Œä½¿æ•´ä¸ª embedding å½¢æˆæ¦‚ç‡åˆ†å¸ƒ\n",
    "    prob = torch.softmax(embeddings, dim=1)  \n",
    "    \n",
    "    # è®¡ç®— log(prob)ï¼Œé˜²æ­¢ log(0)\n",
    "    log_prob = torch.log(torch.clamp(prob, min=1e-8))\n",
    "\n",
    "    # è®¡ç®—å…¨å±€ç†µï¼ˆä½¿ç”¨ sum è®¡ç®—æ•´ä¸ªå›¾çš„ç†µï¼‰\n",
    "    entropy = -torch.sum(prob * log_prob)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import normalize\n",
    "def safe_eval(cell):\n",
    "    if isinstance(cell, str):\n",
    "        return eval(cell, {'Counter': Counter})\n",
    "    return cell\n",
    "\n",
    "def get_i_result(index):\n",
    "    csv_path = f'/workspace/ref/{index}_cooccurrence.csv'\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # Keyword1  Keyword2 Count\n",
    "    # è·å–å”¯ä¸€èŠ‚ç‚¹\n",
    "    #unique_nodes = list(set(df['Keyword1']).union(set(df['Keyword2'])))\n",
    "\n",
    "    # è¿™é‡Œé¢è¿˜è¦åŠ å…¥focus_paperé‡Œçš„èŠ‚ç‚¹\n",
    "    from collections import Counter\n",
    "    def safe_eval(cell):\n",
    "        if isinstance(cell, str):\n",
    "            return eval(cell, {'Counter': Counter})\n",
    "        return cell\n",
    "    all_papers = pd.read_excel('/workspace/ref/æ•´ç†åçš„è·å¥–_1.xlsx')\n",
    "    all_papers['co_occurrence_counter'] = all_papers['co_occurrence_counter'].apply(safe_eval)\n",
    "    focus_cooccurrence = all_papers.loc[index,'co_occurrence_counter']\n",
    "    # åˆ›å»ºä¸€ä¸ªseté›†åˆ\n",
    "    papers_keywords = set()\n",
    "    for node1,node2 in focus_cooccurrence.keys():\n",
    "        papers_keywords.add(node1)\n",
    "        papers_keywords.add(node2)\n",
    "\n",
    "    # å¾—åˆ°æ€»çš„å”¯ä¸€èŠ‚ç‚¹\n",
    "    unique_nodes = list(set(df['Keyword1']).union(set(df['Keyword2']),papers_keywords))\n",
    "\n",
    "    node_to_idx = {node: idx for idx, node in enumerate(unique_nodes)}\n",
    "    # æ„å»ºè¾¹ç´¢å¼•å’Œè¾¹æƒé‡\n",
    "    edge_index = torch.tensor([[node_to_idx[row['Keyword1']], node_to_idx[row['Keyword2']]] for _, row in df.iterrows()]).T\n",
    "    # print(df['Count'].values)\n",
    "    edge_weight = torch.tensor(df['Count'].values, dtype=torch.float32)\n",
    "    # åˆ›å»ºèŠ‚ç‚¹æ–‡æœ¬å­—å…¸\n",
    "    node_texts = {node: node for node in unique_nodes}  # å…³é”®è¯ä½œä¸ºæ–‡æœ¬è¾“å…¥åˆ° BERT\n",
    "\n",
    "    # è®¡ç®—æ‰€æœ‰èŠ‚ç‚¹çš„  ç‰¹å¾ï¼ˆ768 ç»´ï¼‰\n",
    "    node_features = get_embeddings(list(node_texts.values()))\n",
    "\n",
    "    # è®¾å¤‡é€‰æ‹©\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data = Data(x=node_features.to(device), edge_index=edge_index.to(device), edge_attr=edge_weight.to(device))\n",
    "\n",
    "    # åˆå§‹åŒ–æ¨¡å‹\n",
    "    model = GATWithBERT().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # è®­ç»ƒå‚æ•°\n",
    "    num_epochs = 300\n",
    "    patience = 20  # è¿ç»­å¤šå°‘è½® val_loss æ²¡æœ‰ä¸‹é™å°±åœæ­¢\n",
    "    min_delta = 0.0001  # æœ€å° loss ä¸‹é™å¹…åº¦\n",
    "    best_loss = float('inf')\n",
    "    counter = 0  # è®¡æ•°å™¨\n",
    "    best_model_path = f\"/workspace/model/{index}_best_model.pth\"\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(data.x, data.edge_index)\n",
    "\n",
    "        #loss = unsupervised_loss(out, data.edge_index, num_nodes=len(unique_nodes))\n",
    "        #loss = laplacian_loss(out, data.edge_index, data.edge_attr)\n",
    "        loss = neighborhood_loss(out, data.edge_index)\n",
    "        loss += 0.2*entropy_loss(out)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # è®°å½•æœ€ä¼˜æ¨¡å‹\n",
    "        if loss.item() < best_loss-min_delta:\n",
    "            best_loss = loss.item()\n",
    "            counter = 0 # é‡ç½®è®¡æ•°å™¨\n",
    "            torch.save(model.state_dict(), best_model_path)  # ä¿å­˜æ¨¡å‹\n",
    "            #print(f\"âœ… Epoch {epoch}, New Best Loss: {loss.item():.4f}, Model Saved!\")\n",
    "        else:\n",
    "            counter += 1\n",
    "            #print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "            #pass\n",
    "        if counter >= patience:\n",
    "            break\n",
    "    #åŠ è½½æœ€ä¼˜æ¨¡å‹\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    print(\"ğŸ¯ æœ€ä¼˜æ¨¡å‹å·²åŠ è½½ï¼\")\n",
    "    # è·å–æœ€ç»ˆçš„ 256 ç»´åµŒå…¥\n",
    "    final_embeddings = model(data.x, data.edge_index).cpu().detach().numpy()\n",
    "\n",
    "    d_final_embeddings = normalize(final_embeddings,norm='l2',axis=1)\n",
    "\n",
    "    main_file_path = '/workspace/ref/æ•´ç†åçš„è·å¥–_1.xlsx'\n",
    "    all_a_papers = pd.read_excel(main_file_path)\n",
    "    all_a_papers['co_occurrence_counter'] = all_a_papers['co_occurrence_counter'].apply(safe_eval)\n",
    "    focus_cooccurrence = all_a_papers.loc[index,'co_occurrence_counter']\n",
    "\n",
    "    similarities= []\n",
    "    distances = []\n",
    "\n",
    "    # åˆ›å»ºä¸€ä¸ªdfï¼Œç”¨äºå­˜å‚¨node1ã€node2ã€ç›¸ä¼¼åº¦ã€è·ç¦»ï¼Œåé¢æ–¹ä¾¿ä¿å­˜ä¸ºcsv\n",
    "    df = pd.DataFrame(columns=['node1', 'node2', 'similarity', 'distance'])\n",
    "    for node1,node2 in focus_cooccurrence.keys():\n",
    "        # è·å–èŠ‚ç‚¹çš„åµŒå…¥\n",
    "        node1_embedding = d_final_embeddings[node_to_idx[node1]]\n",
    "        node2_embedding = d_final_embeddings[node_to_idx[node2]]\n",
    "        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦\n",
    "        similarity = torch.dot(torch.tensor(node1_embedding), torch.tensor(node2_embedding)) / (\n",
    "                torch.norm(torch.tensor(node1_embedding)) * torch.norm(torch.tensor(node2_embedding)))\n",
    "        # ç›¸ä¼¼åº¦ä¿ç•™5ä½å°æ•°\n",
    "        similarity = round(similarity.item(), 4)\n",
    "        similarities.append(similarity)\n",
    "        #print(f'èŠ‚ç‚¹ {node1} å’ŒèŠ‚ç‚¹ {node2} çš„ç›¸ä¼¼åº¦ä¸º: {similarity}')\n",
    "        # è®¡ç®—è·ç¦»\n",
    "        distance = torch.norm(torch.tensor(node1_embedding) - torch.tensor(node2_embedding), p=2)\n",
    "        distance = round(distance.item(), 4)\n",
    "        distances.append(distance)\n",
    "        #print(f'èŠ‚ç‚¹ {node1} å’ŒèŠ‚ç‚¹ {node2} çš„æ¬§å¼è·ç¦¿ä¸º: {distance}')\n",
    "        # å°†ç»“æœä¿å­˜åˆ°dfä¸­ï¼Œæ–°ç‰ˆçš„pandasä¸æ”¯æŒappendï¼Œæ‰€ä»¥ä½¿ç”¨concat\n",
    "        df = pd.concat([df, pd.DataFrame({'node1': [node1], 'node2': [node2], 'similarity': [similarity], 'distance': [distance]})], ignore_index=True)\n",
    "\n",
    "    # ä¿å­˜ç»“æœ\n",
    "    df.to_csv(f'/workspace/result/{index}_similarity_distance.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===å¤„ç†ç¬¬304ä¸ª==\n",
      "===å¤„ç†ç¬¬305ä¸ª==\n",
      "===å¤„ç†ç¬¬306ä¸ª==\n",
      "ğŸ¯ æœ€ä¼˜æ¨¡å‹å·²åŠ è½½ï¼\n",
      "===å¤„ç†ç¬¬307ä¸ª==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_415/4075709529.py:123: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame({'node1': [node1], 'node2': [node2], 'similarity': [similarity], 'distance': [distance]})], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "all_a_papers = pd.read_excel('/workspace/ref/æ•´ç†åçš„è·å¥–_1.xlsx')\n",
    "all_a_papers = all_a_papers[all_a_papers['title'].notnull()]\n",
    "all_a_papers = all_a_papers[all_a_papers['title']!='nan']\n",
    "indexes = all_a_papers.index\n",
    "for index  in indexes:\n",
    "    if index <=303:\n",
    "        continue\n",
    "    print(f'===å¤„ç†ç¬¬{index}ä¸ª==')\n",
    "    try:\n",
    "        get_i_result(index)\n",
    "    except TypeError as e:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
